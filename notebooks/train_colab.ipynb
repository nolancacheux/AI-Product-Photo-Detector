{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Product Photo Detector -- Training Notebook\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/nolancacheux/AI-Product-Photo-Detector/blob/main/notebooks/train_colab.ipynb)\n",
    "\n",
    "Train an EfficientNet-B0 binary classifier to distinguish **real product photos** from **AI-generated images**.\n",
    "\n",
    "**Requirements:** GPU runtime (T4 recommended). Go to `Runtime > Change runtime type > T4 GPU`.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q torch torchvision timm datasets pillow scikit-learn matplotlib tqdm google-cloud-storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torchvision import transforms\n",
    "import timm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, classification_report, roc_curve, auc\n",
    ")\n",
    "from tqdm.auto import tqdm\n",
    "from PIL import Image\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Reproducibility\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_mem / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration\n",
    "\n",
    "Edit these parameters to customize training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Training Configuration --\n",
    "CONFIG = {\n",
    "    # Dataset\n",
    "    \"dataset_name\": \"date3k2/raw_real_fake_images\",  # HuggingFace dataset ID\n",
    "    \"max_samples_per_class\": 4000,   # Cap per class (None = use all)\n",
    "    \"val_ratio\": 0.15,\n",
    "    \"test_ratio\": 0.15,\n",
    "    \"image_size\": 224,\n",
    "\n",
    "    # Model\n",
    "    \"model_name\": \"efficientnet_b0\",\n",
    "    \"pretrained\": True,\n",
    "    \"dropout\": 0.3,\n",
    "\n",
    "    # Training\n",
    "    \"epochs\": 15,\n",
    "    \"batch_size\": 64,\n",
    "    \"learning_rate\": 1e-4,\n",
    "    \"weight_decay\": 1e-5,\n",
    "    \"patience\": 5,          # Early stopping patience\n",
    "    \"num_workers\": 2,\n",
    "\n",
    "    # Output\n",
    "    \"output_dir\": \"./training_output\",\n",
    "    \"model_filename\": \"best_model.pt\",\n",
    "}\n",
    "\n",
    "os.makedirs(CONFIG[\"output_dir\"], exist_ok=True)\n",
    "print(json.dumps(CONFIG, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Dataset\n",
    "\n",
    "Download from HuggingFace and prepare train/val/test splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Loading dataset: {CONFIG['dataset_name']}...\")\n",
    "raw_dataset = load_dataset(CONFIG[\"dataset_name\"], split=\"train\")\n",
    "print(f\"Total samples: {len(raw_dataset)}\")\n",
    "\n",
    "# Inspect label distribution\n",
    "labels = raw_dataset[\"label\"]\n",
    "unique, counts = np.unique(labels, return_counts=True)\n",
    "label_names = raw_dataset.features[\"label\"].names\n",
    "for u, c in zip(unique, counts):\n",
    "    print(f\"  {label_names[u]}: {c} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HFImageDataset(Dataset):\n",
    "    \"\"\"Wraps a HuggingFace dataset for PyTorch training.\"\"\"\n",
    "\n",
    "    # Map dataset labels to binary: 0 = real, 1 = ai_generated\n",
    "    # Adjust this mapping based on the dataset's label names\n",
    "    LABEL_MAP = None  # Auto-detected below\n",
    "\n",
    "    def __init__(self, hf_dataset, transform=None, label_map=None):\n",
    "        self.dataset = hf_dataset\n",
    "        self.transform = transform\n",
    "        self.label_map = label_map or {}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.dataset[idx]\n",
    "        image = item[\"image\"].convert(\"RGB\")\n",
    "        label = self.label_map.get(item[\"label\"], item[\"label\"])\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "\n",
    "# Auto-detect label mapping: real=0, ai/fake=1\n",
    "label_names_lower = [n.lower() for n in label_names]\n",
    "label_map = {}\n",
    "for i, name in enumerate(label_names_lower):\n",
    "    if any(kw in name for kw in [\"real\", \"authentic\", \"genuine\", \"natural\"]):\n",
    "        label_map[i] = 0  # real\n",
    "    elif any(kw in name for kw in [\"fake\", \"ai\", \"generated\", \"synthetic\", \"art\"]):\n",
    "        label_map[i] = 1  # ai_generated\n",
    "    else:\n",
    "        label_map[i] = i  # keep original\n",
    "\n",
    "print(f\"Label mapping: {label_map}\")\n",
    "for i, name in enumerate(label_names):\n",
    "    print(f\"  {name} (original={i}) -> {label_map[i]} ({'AI-generated' if label_map[i] == 1 else 'Real'})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balance and cap dataset\n",
    "if CONFIG[\"max_samples_per_class\"]:\n",
    "    indices_by_class = {0: [], 1: []}\n",
    "    for idx in range(len(raw_dataset)):\n",
    "        mapped_label = label_map[raw_dataset[idx][\"label\"]]\n",
    "        indices_by_class[mapped_label].append(idx)\n",
    "\n",
    "    cap = CONFIG[\"max_samples_per_class\"]\n",
    "    selected = []\n",
    "    for cls, indices in indices_by_class.items():\n",
    "        random.shuffle(indices)\n",
    "        selected.extend(indices[:cap])\n",
    "        print(f\"  Class {cls}: {min(len(indices), cap)} samples (from {len(indices)})\")\n",
    "\n",
    "    random.shuffle(selected)\n",
    "    raw_dataset = raw_dataset.select(selected)\n",
    "    print(f\"Balanced dataset: {len(raw_dataset)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforms\n",
    "IMG_SIZE = CONFIG[\"image_size\"]\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Split dataset\n",
    "full_dataset = HFImageDataset(raw_dataset, transform=None, label_map=label_map)\n",
    "total = len(full_dataset)\n",
    "val_size = int(total * CONFIG[\"val_ratio\"])\n",
    "test_size = int(total * CONFIG[\"test_ratio\"])\n",
    "train_size = total - val_size - test_size\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = random_split(\n",
    "    full_dataset, [train_size, val_size, test_size],\n",
    "    generator=torch.Generator().manual_seed(SEED)\n",
    ")\n",
    "\n",
    "# Apply different transforms\n",
    "class TransformSubset(Dataset):\n",
    "    def __init__(self, subset, transform):\n",
    "        self.subset = subset\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.subset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image, label = self.subset[idx]\n",
    "        if isinstance(image, Image.Image) and self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "train_ds = TransformSubset(train_dataset, train_transform)\n",
    "val_ds = TransformSubset(val_dataset, val_transform)\n",
    "test_ds = TransformSubset(test_dataset, val_transform)\n",
    "\n",
    "print(f\"Train: {len(train_ds)} | Val: {len(val_ds)} | Test: {len(test_ds)}\")\n",
    "\n",
    "# Dataloaders\n",
    "train_loader = DataLoader(train_ds, batch_size=CONFIG[\"batch_size\"], shuffle=True, num_workers=CONFIG[\"num_workers\"], pin_memory=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=CONFIG[\"batch_size\"], shuffle=False, num_workers=CONFIG[\"num_workers\"], pin_memory=True)\n",
    "test_loader = DataLoader(test_ds, batch_size=CONFIG[\"batch_size\"], shuffle=False, num_workers=CONFIG[\"num_workers\"], pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize samples\n",
    "fig, axes = plt.subplots(2, 8, figsize=(20, 6))\n",
    "fig.suptitle(\"Sample Images (Top: Real, Bottom: AI-Generated)\", fontsize=14)\n",
    "\n",
    "inv_normalize = transforms.Compose([\n",
    "    transforms.Normalize(mean=[0, 0, 0], std=[1/0.229, 1/0.224, 1/0.225]),\n",
    "    transforms.Normalize(mean=[-0.485, -0.456, -0.406], std=[1, 1, 1]),\n",
    "])\n",
    "\n",
    "real_shown, fake_shown = 0, 0\n",
    "for images, labels in train_loader:\n",
    "    for img, lbl in zip(images, labels):\n",
    "        img_show = inv_normalize(img).permute(1, 2, 0).clamp(0, 1).numpy()\n",
    "        if lbl.item() == 0 and real_shown < 8:\n",
    "            axes[0][real_shown].imshow(img_show)\n",
    "            axes[0][real_shown].axis(\"off\")\n",
    "            real_shown += 1\n",
    "        elif lbl.item() == 1 and fake_shown < 8:\n",
    "            axes[1][fake_shown].imshow(img_show)\n",
    "            axes[1][fake_shown].axis(\"off\")\n",
    "            fake_shown += 1\n",
    "        if real_shown >= 8 and fake_shown >= 8:\n",
    "            break\n",
    "    if real_shown >= 8 and fake_shown >= 8:\n",
    "        break\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{CONFIG['output_dir']}/sample_images.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model\n",
    "\n",
    "EfficientNet-B0 with custom binary classification head."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AIImageDetector(nn.Module):\n",
    "    \"\"\"Binary classifier for AI-generated image detection.\"\"\"\n",
    "\n",
    "    def __init__(self, model_name=\"efficientnet_b0\", pretrained=True, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.backbone = timm.create_model(model_name, pretrained=pretrained, num_classes=0)\n",
    "        self.feature_dim = self.backbone.num_features\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(self.feature_dim, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=dropout),\n",
    "            nn.Linear(512, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.backbone(x)\n",
    "        return self.classifier(features)\n",
    "\n",
    "\n",
    "model = AIImageDetector(\n",
    "    model_name=CONFIG[\"model_name\"],\n",
    "    pretrained=CONFIG[\"pretrained\"],\n",
    "    dropout=CONFIG[\"dropout\"],\n",
    ").to(device)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"Feature dimension: {model.feature_dim}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=CONFIG[\"learning_rate\"],\n",
    "    weight_decay=CONFIG[\"weight_decay\"],\n",
    ")\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=CONFIG[\"epochs\"])\n",
    "\n",
    "\n",
    "def train_epoch(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "    for images, labels in tqdm(loader, desc=\"Train\", leave=False):\n",
    "        images = images.to(device)\n",
    "        labels = labels.float().unsqueeze(1).to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * images.size(0)\n",
    "        predicted = (outputs > 0.0).float()\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    return total_loss / total, correct / total\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss, correct, total = 0.0, 0, 0\n",
    "    all_preds, all_labels, all_probs = [], [], []\n",
    "\n",
    "    for images, labels in tqdm(loader, desc=\"Eval\", leave=False):\n",
    "        images = images.to(device)\n",
    "        labels_gpu = labels.float().unsqueeze(1).to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels_gpu)\n",
    "\n",
    "        total_loss += loss.item() * images.size(0)\n",
    "        probs = torch.sigmoid(outputs).cpu()\n",
    "        predicted = (outputs > 0.0).float().cpu()\n",
    "        correct += (predicted == labels_gpu.cpu()).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "        all_preds.extend(predicted.squeeze().numpy())\n",
    "        all_labels.extend(labels.numpy())\n",
    "        all_probs.extend(probs.squeeze().numpy())\n",
    "\n",
    "    metrics = {\n",
    "        \"loss\": total_loss / total,\n",
    "        \"accuracy\": correct / total,\n",
    "        \"precision\": precision_score(all_labels, all_preds, zero_division=0),\n",
    "        \"recall\": recall_score(all_labels, all_preds, zero_division=0),\n",
    "        \"f1\": f1_score(all_labels, all_preds, zero_division=0),\n",
    "    }\n",
    "    return metrics, np.array(all_labels), np.array(all_preds), np.array(all_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop with early stopping\n",
    "best_val_f1 = 0.0\n",
    "patience_counter = 0\n",
    "history = {\"train_loss\": [], \"train_acc\": [], \"val_loss\": [], \"val_acc\": [], \"val_f1\": [], \"lr\": []}\n",
    "\n",
    "print(f\"Training for {CONFIG['epochs']} epochs...\")\n",
    "print(f\"{'Epoch':>5} | {'Train Loss':>10} | {'Train Acc':>9} | {'Val Loss':>8} | {'Val Acc':>7} | {'Val F1':>6} | {'LR':>10}\")\n",
    "print(\"-\" * 75)\n",
    "\n",
    "for epoch in range(CONFIG[\"epochs\"]):\n",
    "    t0 = time.time()\n",
    "\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    val_metrics, _, _, _ = evaluate(model, val_loader, criterion, device)\n",
    "    scheduler.step()\n",
    "\n",
    "    lr = scheduler.get_last_lr()[0]\n",
    "    history[\"train_loss\"].append(train_loss)\n",
    "    history[\"train_acc\"].append(train_acc)\n",
    "    history[\"val_loss\"].append(val_metrics[\"loss\"])\n",
    "    history[\"val_acc\"].append(val_metrics[\"accuracy\"])\n",
    "    history[\"val_f1\"].append(val_metrics[\"f1\"])\n",
    "    history[\"lr\"].append(lr)\n",
    "\n",
    "    elapsed = time.time() - t0\n",
    "    marker = \"\"\n",
    "\n",
    "    if val_metrics[\"f1\"] > best_val_f1:\n",
    "        best_val_f1 = val_metrics[\"f1\"]\n",
    "        patience_counter = 0\n",
    "        marker = \" << best\"\n",
    "\n",
    "        # Save checkpoint\n",
    "        checkpoint = {\n",
    "            \"epoch\": epoch,\n",
    "            \"model_state_dict\": model.state_dict(),\n",
    "            \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "            \"config\": CONFIG,\n",
    "            \"metrics\": val_metrics,\n",
    "            \"history\": history,\n",
    "        }\n",
    "        torch.save(checkpoint, f\"{CONFIG['output_dir']}/{CONFIG['model_filename']}\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "\n",
    "    print(f\"{epoch+1:>5} | {train_loss:>10.4f} | {train_acc:>8.1%} | {val_metrics['loss']:>8.4f} | {val_metrics['accuracy']:>6.1%} | {val_metrics['f1']:>6.3f} | {lr:>10.2e} | {elapsed:.0f}s{marker}\")\n",
    "\n",
    "    if patience_counter >= CONFIG[\"patience\"]:\n",
    "        print(f\"\\nEarly stopping at epoch {epoch+1} (no improvement for {CONFIG['patience']} epochs)\")\n",
    "        break\n",
    "\n",
    "print(f\"\\nBest validation F1: {best_val_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best checkpoint\n",
    "checkpoint = torch.load(f\"{CONFIG['output_dir']}/{CONFIG['model_filename']}\", map_location=device)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "print(f\"Loaded best model from epoch {checkpoint['epoch'] + 1}\")\n",
    "\n",
    "# Evaluate on test set\n",
    "test_metrics, y_true, y_pred, y_probs = evaluate(model, test_loader, criterion, device)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"TEST SET RESULTS\")\n",
    "print(\"=\" * 50)\n",
    "for k, v in test_metrics.items():\n",
    "    print(f\"  {k:>12}: {v:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_pred, target_names=[\"Real\", \"AI-Generated\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training curves\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "axes[0].plot(history[\"train_loss\"], label=\"Train\", linewidth=2)\n",
    "axes[0].plot(history[\"val_loss\"], label=\"Validation\", linewidth=2)\n",
    "axes[0].set_title(\"Loss\", fontsize=13)\n",
    "axes[0].set_xlabel(\"Epoch\")\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].plot(history[\"train_acc\"], label=\"Train\", linewidth=2)\n",
    "axes[1].plot(history[\"val_acc\"], label=\"Validation\", linewidth=2)\n",
    "axes[1].set_title(\"Accuracy\", fontsize=13)\n",
    "axes[1].set_xlabel(\"Epoch\")\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "axes[2].plot(history[\"val_f1\"], label=\"Val F1\", linewidth=2, color=\"green\")\n",
    "axes[2].set_title(\"Validation F1 Score\", fontsize=13)\n",
    "axes[2].set_xlabel(\"Epoch\")\n",
    "axes[2].legend()\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{CONFIG['output_dir']}/training_curves.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix + ROC curve\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "im = axes[0].imshow(cm, interpolation=\"nearest\", cmap=\"Blues\")\n",
    "axes[0].set_title(\"Confusion Matrix\", fontsize=13)\n",
    "axes[0].set_xlabel(\"Predicted\")\n",
    "axes[0].set_ylabel(\"True\")\n",
    "axes[0].set_xticks([0, 1])\n",
    "axes[0].set_yticks([0, 1])\n",
    "axes[0].set_xticklabels([\"Real\", \"AI\"])\n",
    "axes[0].set_yticklabels([\"Real\", \"AI\"])\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        color = \"white\" if cm[i, j] > cm.max() / 2 else \"black\"\n",
    "        axes[0].text(j, i, str(cm[i, j]), ha=\"center\", va=\"center\", color=color, fontsize=16)\n",
    "fig.colorbar(im, ax=axes[0])\n",
    "\n",
    "# ROC curve\n",
    "fpr, tpr, _ = roc_curve(y_true, y_probs)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "axes[1].plot(fpr, tpr, linewidth=2, label=f\"ROC (AUC = {roc_auc:.3f})\")\n",
    "axes[1].plot([0, 1], [0, 1], \"k--\", alpha=0.5)\n",
    "axes[1].set_title(\"ROC Curve\", fontsize=13)\n",
    "axes[1].set_xlabel(\"False Positive Rate\")\n",
    "axes[1].set_ylabel(\"True Positive Rate\")\n",
    "axes[1].legend(fontsize=12)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{CONFIG['output_dir']}/evaluation.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Export and Deploy\n",
    "\n",
    "Save the final metrics and optionally upload to Google Cloud Storage for automated deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save metrics\n",
    "results = {\n",
    "    \"config\": CONFIG,\n",
    "    \"test_metrics\": test_metrics,\n",
    "    \"best_epoch\": int(checkpoint[\"epoch\"]) + 1,\n",
    "    \"total_params\": total_params,\n",
    "    \"history\": history,\n",
    "}\n",
    "with open(f\"{CONFIG['output_dir']}/results.json\", \"w\") as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "model_path = f\"{CONFIG['output_dir']}/{CONFIG['model_filename']}\"\n",
    "model_size_mb = os.path.getsize(model_path) / (1024 * 1024)\n",
    "\n",
    "print(f\"Model saved: {model_path} ({model_size_mb:.1f} MB)\")\n",
    "print(f\"Results saved: {CONFIG['output_dir']}/results.json\")\n",
    "print(f\"\\nTo use this model in the API, copy {CONFIG['model_filename']} to models/checkpoints/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Optional) Upload to GCS for automated Cloud Run deployment\n",
    "# Uncomment and fill in your bucket name to enable\n",
    "\n",
    "UPLOAD_TO_GCS = False  # Set to True to upload\n",
    "GCS_BUCKET = \"ai-product-detector-487013\"  # Your GCS bucket\n",
    "GCS_MODEL_PATH = \"models/best_model.pt\"\n",
    "\n",
    "if UPLOAD_TO_GCS:\n",
    "    from google.cloud import storage\n",
    "\n",
    "    # Authenticate (in Colab: use the auth widget below)\n",
    "    # from google.colab import auth\n",
    "    # auth.authenticate_user()\n",
    "\n",
    "    client = storage.Client()\n",
    "    bucket = client.bucket(GCS_BUCKET)\n",
    "    blob = bucket.blob(GCS_MODEL_PATH)\n",
    "    blob.upload_from_filename(model_path)\n",
    "    print(f\"Uploaded to gs://{GCS_BUCKET}/{GCS_MODEL_PATH}\")\n",
    "    print(\"The CD pipeline will automatically pick up this model on next deploy.\")\n",
    "else:\n",
    "    print(\"GCS upload disabled. To deploy:\")\n",
    "    print(f\"  1. Download {CONFIG['model_filename']} from this notebook\")\n",
    "    print(f\"  2. Place it at models/checkpoints/best_model.pt in the repo\")\n",
    "    print(f\"  3. Push to main -- CD will build and deploy automatically\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the model file (Colab)\n",
    "try:\n",
    "    from google.colab import files\n",
    "    files.download(model_path)\n",
    "    print(\"Download started!\")\n",
    "except ImportError:\n",
    "    print(f\"Not running in Colab. Model is at: {model_path}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

<p align="center">
  <h1 align="center">ğŸ” AI Product Photo Detector</h1>
  <p align="center">
    <strong>Production-grade MLOps system for detecting AI-generated product photos in e-commerce</strong>
  </p>
</p>

<p align="center">
  <a href="https://github.com/nolancacheux/AI-Product-Photo-Detector/actions/workflows/ci.yml"><img src="https://github.com/nolancacheux/AI-Product-Photo-Detector/actions/workflows/ci.yml/badge.svg?branch=main" alt="CI"></a>
  <a href="https://github.com/nolancacheux/AI-Product-Photo-Detector/actions/workflows/cd.yml"><img src="https://github.com/nolancacheux/AI-Product-Photo-Detector/actions/workflows/cd.yml/badge.svg" alt="CD"></a>
  <a href="https://github.com/nolancacheux/AI-Product-Photo-Detector/actions/workflows/model-training.yml"><img src="https://github.com/nolancacheux/AI-Product-Photo-Detector/actions/workflows/model-training.yml/badge.svg" alt="Training"></a>
  <br/>
  <a href="https://www.python.org/"><img src="https://img.shields.io/badge/Python-3.11%20%7C%203.12-3776AB?logo=python&logoColor=white" alt="Python"></a>
  <a href="https://pytorch.org/"><img src="https://img.shields.io/badge/PyTorch-2.0+-EE4C2C?logo=pytorch&logoColor=white" alt="PyTorch"></a>
  <a href="https://fastapi.tiangolo.com/"><img src="https://img.shields.io/badge/FastAPI-0.100+-009688?logo=fastapi&logoColor=white" alt="FastAPI"></a>
  <a href="https://cloud.google.com/run"><img src="https://img.shields.io/badge/Cloud%20Run-Deployed-4285F4?logo=googlecloud&logoColor=white" alt="Cloud Run"></a>
  <a href="https://docker.com/"><img src="https://img.shields.io/badge/Docker-Ready-2496ED?logo=docker&logoColor=white" alt="Docker"></a>
  <a href="https://dvc.org/"><img src="https://img.shields.io/badge/DVC-Pipeline-945DD6?logo=dvc&logoColor=white" alt="DVC"></a>
  <a href="https://github.com/nolancacheux/AI-Product-Photo-Detector/blob/main/LICENSE"><img src="https://img.shields.io/badge/License-MIT-yellow.svg" alt="License"></a>
  <a href="https://colab.research.google.com/github/nolancacheux/AI-Product-Photo-Detector/blob/main/notebooks/train_colab.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"></a>
</p>

<p align="center">
  End-to-end machine learning system â€” from data ingestion and GPU training on Vertex AI<br/>
  to API serving, real-time monitoring, and automated cloud deployment.
</p>

---

## ğŸ“‘ Table of Contents

- [Live Demo](#-live-demo)
- [Architecture](#-architecture)
  - [System Overview](#system-overview)
  - [CI/CD Pipeline](#cicd-pipeline)
  - [ML Pipeline](#ml-pipeline)
- [Features](#-features)
- [Quick Start](#-quick-start)
  - [Local Development](#local-development)
  - [Production Deployment](#production-deployment)
- [API Documentation](#-api-documentation)
  - [Endpoints](#endpoints)
  - [Authentication](#authentication)
  - [Error Responses](#error-responses)
- [MLOps Pipeline](#-mlops-pipeline)
  - [Training Options](#training-options)
  - [DVC Pipeline](#dvc-pipeline)
  - [Training Configuration](#training-configuration)
- [Monitoring & Observability](#-monitoring--observability)
  - [Prometheus Metrics](#prometheus-metrics)
  - [Drift Detection](#drift-detection)
  - [Grafana Dashboards](#grafana-dashboards)
- [Tech Stack](#-tech-stack)
- [Project Structure](#-project-structure)
- [Docker](#-docker)
- [Cloud Deployment](#-cloud-deployment)
- [Contributing](#-contributing)
- [Documentation](#-documentation)
- [License](#-license)

---

## ğŸŒ Live Demo

| Resource | URL |
|----------|-----|
| **ğŸš€ REST API** | [`ai-product-detector-714127049161.europe-west1.run.app`](https://ai-product-detector-714127049161.europe-west1.run.app) |
| **ğŸ–¥ï¸ Web UI** | [`ai-product-detector-ui-714127049161.europe-west1.run.app`](https://ai-product-detector-ui-714127049161.europe-west1.run.app) |
| **ğŸ“– Swagger Docs** | [`/docs`](https://ai-product-detector-714127049161.europe-west1.run.app/docs) |
| **ğŸ“Š Health Check** | [`/health`](https://ai-product-detector-714127049161.europe-west1.run.app/health) |
| **ğŸ“ˆ Metrics** | [`/metrics`](https://ai-product-detector-714127049161.europe-west1.run.app/metrics) |

```bash
# Try it now â€” single prediction
curl -X POST https://ai-product-detector-714127049161.europe-west1.run.app/predict \
  -H "X-API-Key: YOUR_API_KEY" \
  -F "file=@product_photo.jpg"
```

---

## ğŸ—ï¸ Architecture

### System Overview

```mermaid
graph TB
    subgraph Clients["Client Layer"]
        CLI[cURL / HTTPie]
        UI[Streamlit UI]
        SDK[Python SDK]
    end

    subgraph CloudRun["Google Cloud Run"]
        API[FastAPI Server]
        AUTH[Auth Middleware]
        RL[Rate Limiter]
        PRED[Predictor Engine]
        EXPL[Grad-CAM Explainer]
        DRIFT[Drift Detector]
        METRICS[Prometheus Metrics]
    end

    subgraph Storage["Google Cloud Storage"]
        GCS_DATA[Training Data]
        GCS_MODELS[Model Checkpoints]
        GCS_STAGING[Vertex AI Staging]
    end

    subgraph Registry["Artifact Registry"]
        IMG_API[API Image]
        IMG_TRAIN[Training Image]
        IMG_UI[UI Image]
    end

    subgraph Training["Vertex AI"]
        VERTEX[Custom Training Job]
        GPU["n1-standard-4 + T4 GPU"]
    end

    subgraph Monitoring["Observability"]
        PROM[Prometheus]
        GRAF[Grafana Dashboards]
        LOGS[Structured Logging]
    end

    CLI --> API
    UI --> API
    SDK --> API
    API --> AUTH --> RL --> PRED
    API --> EXPL
    API --> DRIFT
    API --> METRICS
    PRED --> GCS_MODELS
    VERTEX --> GPU
    GPU --> GCS_MODELS
    GCS_DATA --> VERTEX
    IMG_TRAIN --> VERTEX
    IMG_API --> CloudRun
    METRICS --> PROM --> GRAF
    API --> LOGS

    style CloudRun fill:#e8f5e9,stroke:#2e7d32
    style Training fill:#e3f2fd,stroke:#1565c0
    style Storage fill:#fff3e0,stroke:#ef6c00
    style Monitoring fill:#fce4ec,stroke:#c62828
```

### CI/CD Pipeline

```mermaid
graph LR
    subgraph CI["CI Pipeline"]
        PUSH[Git Push] --> LINT[Ruff Lint]
        PUSH --> TYPE[mypy Type Check]
        PUSH --> TEST["pytest\n3.11 + 3.12"]
        PUSH --> SEC[Security Scan]
        LINT --> DBUILD[Docker Build Test]
        TEST --> DBUILD
    end

    subgraph CD["CD Pipeline"]
        DBUILD --> WAIT[Wait for CI]
        WAIT --> BUILD[Build Image]
        BUILD --> PUSH_REG[Push to\nArtifact Registry]
        PUSH_REG --> DEPLOY[Deploy to\nCloud Run]
        DEPLOY --> SMOKE[Smoke Test]
    end

    subgraph ModelCD["Model Training Pipeline"]
        TRIGGER[Manual Dispatch] --> DATA[Verify GCS Data]
        DATA --> TBUILD[Build Training Image]
        TBUILD --> VTRAIN["Vertex AI\nGPU Training"]
        VTRAIN --> EVAL[Evaluate Model]
        EVAL --> GATE{"Quality Gate\nacc â‰¥ 0.85\nF1 â‰¥ 0.80"}
        GATE -->|Pass| MDEPLOY[Deploy New Model]
        GATE -->|Fail| REJECT[Block Deploy]
    end

    style CI fill:#e8f5e9,stroke:#2e7d32
    style CD fill:#e3f2fd,stroke:#1565c0
    style ModelCD fill:#fff3e0,stroke:#ef6c00
```

### ML Pipeline

```mermaid
graph LR
    subgraph Data["Data Stage"]
        HF[HuggingFace\nDatasets] --> DL[Download]
        CIFAKE[CIFAKE\nDataset] --> DL
        DL --> VAL[Validate\nIntegrity]
        VAL --> SPLIT["Train / Val / Test\nSplit"]
    end

    subgraph Train["Training Stage"]
        SPLIT --> AUG[Augmentation\nFlip, Rotate, Jitter]
        AUG --> MODEL["EfficientNet-B0\nTransfer Learning"]
        MODEL --> OPT["AdamW + Cosine\nAnnealing"]
        OPT --> CKPT[Checkpoint\nbest_model.pt]
    end

    subgraph Evaluate["Evaluation Stage"]
        CKPT --> METRICS_E[Accuracy, F1\nPrecision, Recall]
        METRICS_E --> GATE_E{"Quality Gate"}
        GATE_E -->|Pass| REG[Model Registry\nGCS + MLflow]
        GATE_E -->|Fail| RETRAIN[Retrain]
    end

    subgraph Deploy["Deploy Stage"]
        REG --> DOCKER[Docker Build]
        DOCKER --> CR[Cloud Run Deploy]
        CR --> MONITOR[Monitor\nDrift Detection]
        MONITOR -->|Drift| RETRAIN
    end

    style Data fill:#f3e5f5,stroke:#7b1fa2
    style Train fill:#e8f5e9,stroke:#2e7d32
    style Evaluate fill:#e3f2fd,stroke:#1565c0
    style Deploy fill:#fff3e0,stroke:#ef6c00
```

---

## âœ¨ Features

### ğŸ§  Core ML
- **Binary image classification** â€” Real vs AI-generated product photos
- **EfficientNet-B0 backbone** â€” Transfer learning with pretrained ImageNet weights via `timm`
- **Grad-CAM explainability** â€” Visual heatmaps showing which regions drive the prediction
- **Data augmentation** â€” Horizontal flip, rotation, color jitter, random crop
- **Cosine annealing** â€” Learning rate scheduling with warmup

### ğŸš€ API & Serving
- **FastAPI async server** â€” Single, batch (up to 10), and explainability endpoints
- **API key authentication** â€” HMAC-based constant-time comparison
- **Rate limiting** â€” Per-endpoint configurable limits via `slowapi`
- **Input validation** â€” File type, size, and format verification
- **Structured responses** â€” Pydantic v2 schemas with confidence levels

### ğŸ”„ MLOps
- **DVC pipelines** â€” Reproducible `download â†’ validate â†’ train` workflow
- **MLflow experiment tracking** â€” Hyperparameters, metrics, and model artifacts
- **Vertex AI training** â€” Automated GPU training with T4 on GCP
- **Quality gate** â€” Automated accuracy/F1 thresholds before deployment
- **Model versioning** â€” GCS-backed model registry with DVC tracking

### ğŸ“Š Monitoring & Observability
- **Prometheus metrics** â€” 12+ custom metrics (latency, throughput, probability distribution)
- **Grafana dashboards** â€” Pre-configured, auto-provisioned dashboards
- **Drift detection** â€” Real-time prediction distribution monitoring (sliding window)
- **Structured logging** â€” JSON output via `structlog` with request ID correlation

### ğŸ” Security
- **API key auth** â€” Optional, enforced in production via environment variables
- **Rate limiting** â€” Abuse prevention on all prediction endpoints
- **Non-root containers** â€” Docker images run as unprivileged users
- **Security scanning** â€” `pip-audit` + `bandit` in CI pipeline
- **CORS configuration** â€” Configurable allowed origins

### ğŸ—ï¸ Infrastructure
- **Terraform IaC** â€” Modular setup: GCS, Artifact Registry, Cloud Run, IAM, budget alerts
- **Docker Compose** â€” Full local stack (API + UI + MLflow + Prometheus + Grafana)
- **GitHub Actions CI/CD** â€” Automated lint, test, build, deploy on every push
- **Serverless scaling** â€” Cloud Run auto-scales 0â†’N based on traffic

---

## ğŸš€ Quick Start

The project supports **three development modes** â€” choose based on your needs:

| Mode | Best For | GPU | Time |
|------|----------|-----|------|
| **ğŸ–¥ï¸ Local** | Development, debugging | CPU | 1-2h |
| **â˜ï¸ Colab** | Free GPU experiments | T4/A100 | ~20 min |
| **ğŸš€ Production** | CI/CD, production releases | T4 (Vertex AI) | ~25 min |

### ğŸ–¥ï¸ Mode 1: Local Development (Docker Compose)

Full-stack local development with hot reload, debugging, and monitoring.

**Prerequisites:** Python 3.11+, [uv](https://docs.astral.sh/uv/) (recommended) or pip, Docker & Docker Compose

```bash
# 1. Clone and setup
git clone https://github.com/nolancacheux/AI-Product-Photo-Detector.git
cd AI-Product-Photo-Detector

# 2. Install dependencies (includes pre-commit hooks)
make dev

# 3. Download dataset
make data           # CIFAKE (2500 images/class)

# 4. Start the full stack
make docker-up      # API + UI + MLflow + Prometheus + Grafana
```

**Service URLs:**

| Service | URL | Description |
|---------|-----|-------------|
| **API** | http://localhost:8080 | FastAPI inference server |
| **Streamlit UI** | http://localhost:8501 | Drag-and-drop image analysis |
| **MLflow** | http://localhost:5000 | Experiment tracking UI |
| **Prometheus** | http://localhost:9090 | Metrics collection |
| **Grafana** | http://localhost:3000 | Monitoring dashboards (admin/admin) |

**Development commands:**

```bash
# Training (CPU)
make train              # Train with configs/train_config.yaml
python -m src.training.train --config configs/train_config.yaml --epochs 10

# Code quality
make lint               # ruff + mypy
make test               # pytest with coverage
make format             # Auto-format code

# Docker
make docker-logs        # Follow logs
make docker-down        # Stop all services
make docker-dev         # Dev stack with hot reload
```

### â˜ï¸ Mode 2: Google Colab (Free GPU Training)

Train on free T4/A100 GPUs without local setup.

1. **Open the notebook:**
   [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/nolancacheux/AI-Product-Photo-Detector/blob/main/notebooks/train_colab.ipynb)

2. **Select GPU runtime:**
   - Go to **Runtime â†’ Change runtime type â†’ T4 GPU**

3. **Run all cells** â€” the notebook handles:
   - Environment setup
   - Data loading (HuggingFace or GCS)
   - Training with progress bars
   - Model export

4. **Export model:**
   - Download from Colab, or
   - Auto-upload to GCS bucket

**Configuration in notebook:**
```python
CONFIG = {
    "epochs": 15,
    "batch_size": 64,      # Reduce to 32 if OOM
    "learning_rate": 0.001,
    "gcs_bucket": "ai-product-detector-487013",  # Optional
}
```

### ğŸš€ Mode 3: Production GCP (CI/CD)

Automated deployment with GitHub Actions, Vertex AI training, and Cloud Run serving.

```bash
# 1. Provision infrastructure
cd terraform/environments/prod
terraform init && terraform apply

# 2. Push to main â€” CI/CD handles the rest
git push origin main
# CI: lint â†’ type-check â†’ test (3.11 + 3.12) â†’ security scan
# CD: build image â†’ push to Artifact Registry â†’ deploy to Cloud Run â†’ smoke test

# 3. Trigger GPU training on Vertex AI
gh workflow run model-training.yml \
  -f epochs=15 \
  -f batch_size=64 \
  -f auto_deploy=true
```

**Training pipeline stages:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Verify Data  â”‚ â†’ â”‚ Build Image  â”‚ â†’ â”‚ Vertex AI    â”‚ â†’ â”‚ Evaluate     â”‚
â”‚ (GCS)        â”‚   â”‚ (Artifact    â”‚   â”‚ GPU Training â”‚   â”‚ (Quality     â”‚
â”‚              â”‚   â”‚  Registry)   â”‚   â”‚ (T4)         â”‚   â”‚  Gate)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                                â”‚
                                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                              â”‚                 â”‚                 â”‚
                                            PASS              FAIL
                                              â”‚                 â”‚
                                        Auto Deploy        Block Deploy
                                        (Cloud Run)
```

**Quality Gate:** Accuracy â‰¥ 0.85, F1 â‰¥ 0.80

**Production URLs:**

| Resource | URL |
|----------|-----|
| **API** | https://ai-product-detector-714127049161.europe-west1.run.app |
| **UI** | https://ai-product-detector-ui-714127049161.europe-west1.run.app |
| **Swagger** | https://ai-product-detector-714127049161.europe-west1.run.app/docs |

See [docs/TRAINING.md](docs/TRAINING.md) for detailed instructions on each mode.

---

## ğŸ“¡ API Documentation

**Base URL:** `https://ai-product-detector-714127049161.europe-west1.run.app`
&nbsp;|&nbsp; **Interactive docs:** [`/docs`](https://ai-product-detector-714127049161.europe-west1.run.app/docs)

### Endpoints

| Method | Endpoint | Description | Rate Limit |
|--------|----------|-------------|------------|
| `POST` | `/predict` | Single image classification | 30/min |
| `POST` | `/predict/batch` | Batch classification (up to 10) | 5/min |
| `POST` | `/predict/explain` | Prediction + Grad-CAM heatmap | 10/min |
| `GET` | `/health` | Readiness probe (model status, uptime, drift) | â€” |
| `GET` | `/healthz` | Lightweight liveness probe | â€” |
| `GET` | `/metrics` | Prometheus metrics (text format) | â€” |
| `GET` | `/drift` | Drift detection status | â€” |
| `GET` | `/privacy` | GDPR privacy policy | â€” |

### Single Prediction

```bash
curl -X POST https://ai-product-detector-714127049161.europe-west1.run.app/predict \
  -H "X-API-Key: YOUR_API_KEY" \
  -F "file=@product_photo.jpg"
```

```json
{
  "prediction": "ai_generated",
  "probability": 0.87,
  "confidence": "high",
  "inference_time_ms": 45.2,
  "model_version": "1.0.0"
}
```

### Batch Prediction

```bash
curl -X POST https://ai-product-detector-714127049161.europe-west1.run.app/predict/batch \
  -H "X-API-Key: YOUR_API_KEY" \
  -F "files=@photo1.jpg" \
  -F "files=@photo2.png"
```

```json
{
  "results": [
    { "filename": "photo1.jpg", "prediction": "ai_generated", "probability": 0.87, "confidence": "high" },
    { "filename": "photo2.png", "prediction": "real", "probability": 0.12, "confidence": "high" }
  ],
  "total": 2,
  "successful": 2,
  "failed": 0,
  "total_inference_time_ms": 89.5
}
```

### Explainability (Grad-CAM)

```bash
curl -X POST https://ai-product-detector-714127049161.europe-west1.run.app/predict/explain \
  -H "X-API-Key: YOUR_API_KEY" \
  -F "file=@product_photo.jpg"
```

```json
{
  "prediction": "ai_generated",
  "probability": 0.87,
  "confidence": "high",
  "heatmap_base64": "/9j/4AAQ...",
  "inference_time_ms": 120.5
}
```

### Authentication

| Variable | Description |
|----------|-------------|
| `API_KEYS` | Comma-separated list of valid API keys |
| `REQUIRE_AUTH` | Set to `true` to enforce auth (default: disabled for local dev) |

Pass the key via header: `X-API-Key: YOUR_KEY`

### Error Responses

```json
{ "error": "Invalid image format", "detail": "Supported formats: JPEG, PNG, WebP. Got: image/gif" }
```

| Status | Meaning |
|--------|---------|
| `400` | Invalid input (bad format, empty batch) |
| `401` | Missing or invalid API key |
| `413` | File too large (>5 MB) or batch payload >50 MB |
| `429` | Rate limit exceeded |
| `503` | Model not loaded / service starting |

---

## ğŸ”¬ MLOps Pipeline

### Training Options

| | **Google Colab** | **Vertex AI** | **Local** |
|---|---|---|---|
| **GPU** | Free T4 | T4 on GCP (paid) | CPU or local GPU |
| **Cost** | Free | ~$0.10â€“0.20/run | Free |
| **Time** | ~20 min | ~25 min | ~1â€“2h (CPU) |
| **Dataset** | HuggingFace (high-res) | GCS (auto-uploaded) | CIFAKE (DVC) |
| **Best for** | Quick experiments | Production retraining | Development |

#### Colab (Quick Start)

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/nolancacheux/AI-Product-Photo-Detector/blob/main/notebooks/train_colab.ipynb)

Open â†’ set runtime to T4 GPU â†’ run all cells â†’ download checkpoint.

#### Vertex AI (Production)

```bash
# Trigger via GitHub Actions
gh workflow run model-training.yml -f epochs=15 -f batch_size=64 -f auto_deploy=true

# Or submit directly
python -m src.training.vertex_submit --epochs 15 --batch-size 64 --sync
```

**Pipeline stages:**

```
[1] Verify Data â†’ [2] Build Image â†’ [3] GPU Training â†’ [4] Evaluate â†’ [5] Quality Gate â†’ [6] Deploy
     (GCS)        (Artifact Reg.)    (Vertex AI T4)      (CPU)        (accâ‰¥0.85,F1â‰¥0.80)  (Cloud Run)
```

#### Local Training

```bash
make data            # Download CIFAKE dataset
make train           # Train with configs/train_config.yaml
make dvc-repro       # Full DVC pipeline: download â†’ validate â†’ train
make mlflow          # Start MLflow UI â†’ http://localhost:5000
```

### DVC Pipeline

```yaml
# dvc.yaml â€” 3-stage reproducible pipeline
stages:
  download:   # Download CIFAKE dataset â†’ data/processed/
  validate:   # Integrity checks â†’ reports/data_validation.json
  train:      # EfficientNet-B0 â†’ models/checkpoints/best_model.pt
```

```bash
dvc repro            # Run full pipeline
dvc repro train      # Re-run training only
dvc status           # Check what changed
```

### Training Configuration

| Parameter | Value |
|-----------|-------|
| Architecture | EfficientNet-B0 (ImageNet pretrained) |
| Image size | 224 Ã— 224 |
| Batch size | 64 |
| Epochs | 15 |
| Optimizer | AdamW, lr=0.001 |
| Scheduler | Cosine annealing with 2-epoch warmup |
| Early stopping | Patience: 5 epochs |
| Augmentation | Flip, rotation, color jitter, random crop |

---

## ğŸ“Š Monitoring & Observability

### Prometheus Metrics

All exposed at `GET /metrics` in Prometheus text format:

| Metric | Type | Description |
|--------|------|-------------|
| `aidetect_predictions_total` | Counter | Total predictions by status / class / confidence |
| `aidetect_prediction_latency_seconds` | Histogram | Per-prediction latency distribution |
| `aidetect_prediction_probability` | Histogram | Probability score distribution |
| `aidetect_batch_predictions_total` | Counter | Batch request count |
| `aidetect_batch_size` | Histogram | Images per batch request |
| `aidetect_batch_latency_seconds` | Histogram | Batch processing time |
| `aidetect_image_validation_errors_total` | Counter | Validation errors by type |
| `aidetect_model_loaded` | Gauge | Model load status (0/1) |
| `aidetect_request_size_bytes` | Histogram | Request payload size |
| `aidetect_response_size_bytes` | Histogram | Response payload size |
| `http_request_duration_seconds` | Histogram | HTTP latency by endpoint |
| `http_requests_total` | Counter | HTTP requests by method / endpoint / status |

### Drift Detection

Real-time monitoring of prediction distribution shifts:

- **Sliding window** over the last 1,000 predictions
- **Tracked signals:** Mean probability, confidence distribution, class ratios
- **Alerting:** Configurable threshold with status at `GET /drift`
- **Feedback loop:** Drift triggers model retraining consideration

### Grafana Dashboards

Pre-configured and auto-provisioned via `configs/grafana/provisioning/`:

- **Request throughput** â€” Requests/sec by endpoint
- **Latency percentiles** â€” p50, p90, p99 per endpoint
- **Prediction distribution** â€” Real vs AI-generated ratio over time
- **Model health** â€” Load status, drift alerts, error rates

Default credentials: `admin` / `admin`

### Structured Logging

```json
{
  "event": "prediction_complete",
  "prediction": "ai_generated",
  "probability": 0.87,
  "latency_ms": 45.2,
  "request_id": "abc-123",
  "timestamp": "2024-01-15T10:30:00Z"
}
```

- `structlog` with JSON output
- Request ID tracking via `X-Request-ID` header
- Cloud Trace context correlation (GCP)

---

## ğŸ› ï¸ Tech Stack

| Category | Technologies |
|----------|-------------|
| **Deep Learning** | PyTorch 2.0+, torchvision, timm (EfficientNet-B0), Grad-CAM |
| **API Framework** | FastAPI, Uvicorn, Pydantic v2, slowapi |
| **Data & MLOps** | DVC (pipelines + versioning), MLflow (experiment tracking), HuggingFace Datasets |
| **Cloud Training** | Vertex AI (CustomContainerTrainingJob), T4 GPU, Google Cloud Storage |
| **Monitoring** | Prometheus, Grafana, structlog (JSON), custom drift detection |
| **Infrastructure** | Docker, Docker Compose, Terraform (modular), GCP Cloud Run, Artifact Registry |
| **CI/CD** | GitHub Actions (4 workflows: CI, CD, Model Training, PR Preview) |
| **Code Quality** | Ruff (lint + format), mypy (strict), pytest + coverage, pre-commit |
| **Load Testing** | Locust, k6 |
| **Security** | pip-audit, bandit, HMAC auth, non-root containers |
| **UI** | Streamlit (deployed on Cloud Run) |

---

## ğŸ“ Project Structure

```
AI-Product-Photo-Detector/
â”‚
â”œâ”€â”€ .github/workflows/
â”‚   â”œâ”€â”€ ci.yml                          # CI: lint + type-check + test (3.11, 3.12) + security
â”‚   â”œâ”€â”€ cd.yml                          # CD: build â†’ push â†’ deploy Cloud Run â†’ smoke test
â”‚   â”œâ”€â”€ model-training.yml              # Vertex AI: data â†’ train (GPU) â†’ eval â†’ gate â†’ deploy
â”‚   â””â”€â”€ pr-preview.yml                  # PR preview deployments
â”‚
â”œâ”€â”€ configs/
â”‚   â”œâ”€â”€ grafana/                        # Grafana dashboard definitions + provisioning
â”‚   â”œâ”€â”€ prometheus/                     # Prometheus alerting rules
â”‚   â”œâ”€â”€ inference_config.yaml           # API server configuration
â”‚   â”œâ”€â”€ pipeline_config.yaml            # Vertex AI pipeline parameters
â”‚   â”œâ”€â”€ prometheus.yml                  # Prometheus scrape targets
â”‚   â””â”€â”€ train_config.yaml               # Training hyperparameters
â”‚
â”œâ”€â”€ docker/
â”‚   â”œâ”€â”€ Dockerfile                      # Production API image (CPU PyTorch, non-root)
â”‚   â”œâ”€â”€ Dockerfile.training             # Vertex AI GPU training image
â”‚   â”œâ”€â”€ serve.Dockerfile                # Serving-optimized image
â”‚   â”œâ”€â”€ train.Dockerfile                # Local training environment
â”‚   â””â”€â”€ ui.Dockerfile                   # Streamlit UI image
â”‚
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ ARCHITECTURE.md                 # System architecture & design decisions
â”‚   â”œâ”€â”€ CICD.md                         # CI/CD pipeline documentation
â”‚   â”œâ”€â”€ CONTRIBUTING.md                 # Contribution guidelines
â”‚   â”œâ”€â”€ COSTS.md                        # Cloud cost analysis
â”‚   â”œâ”€â”€ DEPLOYMENT.md                   # Deployment guide
â”‚   â”œâ”€â”€ INCIDENT_SCENARIO.md            # Incident response playbook
â”‚   â”œâ”€â”€ INFRASTRUCTURE.md               # Infrastructure documentation
â”‚   â”œâ”€â”€ MONITORING.md                   # Monitoring & observability guide
â”‚   â”œâ”€â”€ PRD.md                          # Product requirements document
â”‚   â””â”€â”€ TRAINING.md                     # Training pipeline documentation
â”‚
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ train_colab.ipynb               # Colab notebook â€” free T4 GPU training
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ create_sample_data.py           # Generate sample test images
â”‚   â”œâ”€â”€ download_cifake.py              # Download CIFAKE dataset
â”‚   â”œâ”€â”€ download_dataset.py             # Generic dataset downloader
â”‚   â””â”€â”€ download_utils.py               # Shared download utilities
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â””â”€â”€ validate.py                 # Dataset validation & integrity checks
â”‚   â”œâ”€â”€ inference/
â”‚   â”‚   â”œâ”€â”€ api.py                      # FastAPI application & routes
â”‚   â”‚   â”œâ”€â”€ auth.py                     # API key auth (HMAC, constant-time)
â”‚   â”‚   â”œâ”€â”€ explainer.py                # Grad-CAM heatmap generation
â”‚   â”‚   â”œâ”€â”€ predictor.py                # Model inference engine
â”‚   â”‚   â”œâ”€â”€ rate_limit.py               # Rate limiting configuration
â”‚   â”‚   â”œâ”€â”€ routes/                     # Modular API routes
â”‚   â”‚   â”‚   â”œâ”€â”€ info.py                 # Info endpoints (/, /privacy)
â”‚   â”‚   â”‚   â”œâ”€â”€ monitoring.py           # Health & metrics endpoints
â”‚   â”‚   â”‚   â”œâ”€â”€ predict.py              # Prediction endpoints
â”‚   â”‚   â”‚   â””â”€â”€ v1/                     # API v1 versioned routes
â”‚   â”‚   â”œâ”€â”€ schemas.py                  # Pydantic request/response models
â”‚   â”‚   â”œâ”€â”€ shadow.py                   # Shadow model comparison (A/B testing)
â”‚   â”‚   â”œâ”€â”€ state.py                    # Application state management
â”‚   â”‚   â””â”€â”€ validation.py               # Image validation utilities
â”‚   â”œâ”€â”€ monitoring/
â”‚   â”‚   â”œâ”€â”€ drift.py                    # Real-time drift detection
â”‚   â”‚   â””â”€â”€ metrics.py                  # Prometheus metric definitions
â”‚   â”œâ”€â”€ pipelines/
â”‚   â”‚   â”œâ”€â”€ evaluate.py                 # Model evaluation pipeline stage
â”‚   â”‚   â””â”€â”€ training_pipeline.py        # End-to-end training orchestrator
â”‚   â”œâ”€â”€ training/
â”‚   â”‚   â”œâ”€â”€ augmentation.py             # Data augmentation transforms
â”‚   â”‚   â”œâ”€â”€ dataset.py                  # PyTorch Dataset implementation
â”‚   â”‚   â”œâ”€â”€ gcs.py                      # GCS upload/download helpers
â”‚   â”‚   â”œâ”€â”€ model.py                    # EfficientNet-B0 architecture
â”‚   â”‚   â”œâ”€â”€ train.py                    # Training loop with MLflow tracking
â”‚   â”‚   â””â”€â”€ vertex_submit.py            # Vertex AI job submission CLI
â”‚   â”œâ”€â”€ ui/
â”‚   â”‚   â””â”€â”€ app.py                      # Streamlit web interface
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ config.py                   # Settings management (Pydantic Settings)
â”‚       â”œâ”€â”€ logger.py                   # Structured logging setup
â”‚       â””â”€â”€ model_loader.py             # Model loading utilities
â”‚
â”œâ”€â”€ terraform/
â”‚   â”œâ”€â”€ environments/
â”‚   â”‚   â”œâ”€â”€ dev/                        # Development environment config
â”‚   â”‚   â””â”€â”€ prod/                       # Production environment config
â”‚   â”œâ”€â”€ modules/
â”‚   â”‚   â”œâ”€â”€ artifact_registry/          # Artifact Registry module
â”‚   â”‚   â”œâ”€â”€ budget/                     # Budget alerts module
â”‚   â”‚   â”œâ”€â”€ cloud_run/                  # Cloud Run service module
â”‚   â”‚   â”œâ”€â”€ iam/                        # IAM bindings module
â”‚   â”‚   â”œâ”€â”€ secrets/                    # Secret Manager module
â”‚   â”‚   â”œâ”€â”€ storage/                    # GCS bucket module
â”‚   â”‚   â””â”€â”€ vertex_ai/                  # Vertex AI resources module
â”‚   â”œâ”€â”€ backend.tf                      # Terraform state backend (GCS)
â”‚   â””â”€â”€ versions.tf                     # Provider version constraints
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ load/
â”‚   â”‚   â”œâ”€â”€ locustfile.py               # Locust load testing scenarios
â”‚   â”‚   â””â”€â”€ k6_test.js                  # k6 load testing script
â”‚   â”œâ”€â”€ conftest.py                     # Shared test fixtures
â”‚   â”œâ”€â”€ test_api.py                     # API endpoint tests
â”‚   â”œâ”€â”€ test_augmentation.py            # Augmentation tests
â”‚   â”œâ”€â”€ test_auth.py                    # Authentication tests
â”‚   â”œâ”€â”€ test_batch.py                   # Batch prediction tests
â”‚   â”œâ”€â”€ test_config.py                  # Configuration tests
â”‚   â”œâ”€â”€ test_data_validate.py           # Data validation tests
â”‚   â”œâ”€â”€ test_dataset.py                 # Dataset tests
â”‚   â”œâ”€â”€ test_drift.py                   # Drift detection tests
â”‚   â”œâ”€â”€ test_explainer.py               # Grad-CAM tests
â”‚   â”œâ”€â”€ test_gcs.py                     # GCS helper tests
â”‚   â”œâ”€â”€ test_integration.py             # Integration tests
â”‚   â”œâ”€â”€ test_logger.py                  # Logger tests
â”‚   â”œâ”€â”€ test_metrics.py                 # Prometheus metrics tests
â”‚   â”œâ”€â”€ test_model.py                   # Model architecture tests
â”‚   â”œâ”€â”€ test_pipelines.py               # Pipeline orchestration tests
â”‚   â”œâ”€â”€ test_predictor.py               # Inference engine tests
â”‚   â”œâ”€â”€ test_shadow.py                  # Shadow A/B testing tests
â”‚   â”œâ”€â”€ test_state.py                   # Application state tests
â”‚   â”œâ”€â”€ test_train.py                   # Training loop tests
â”‚   â”œâ”€â”€ test_ui.py                      # UI tests
â”‚   â”œâ”€â”€ test_validation.py              # Validation tests
â”‚   â””â”€â”€ test_vertex_submit.py           # Vertex AI submission tests
â”‚
â”œâ”€â”€ docker-compose.yml                  # Full stack: API + UI + MLflow + Prometheus + Grafana
â”œâ”€â”€ dvc.yaml                            # DVC pipeline: download â†’ validate â†’ train
â”œâ”€â”€ Makefile                            # Development commands (make help)
â”œâ”€â”€ pyproject.toml                      # Project metadata, dependencies, tool config
â””â”€â”€ .pre-commit-config.yaml             # Pre-commit hooks (ruff)
```

---

## ğŸ³ Docker

```bash
# Build API image
docker build -f docker/Dockerfile -t ai-product-detector:latest .

# Run standalone
docker run --rm -p 8080:8080 -v ./models:/app/models:ro ai-product-detector:latest

# Full stack (API + UI + MLflow + Prometheus + Grafana)
docker compose up -d
docker compose logs -f
docker compose down
```

---

## â˜ï¸ Cloud Deployment

### Cloud Run Services

| Service | Region | URL |
|---------|--------|-----|
| **API** | europe-west1 | [`ai-product-detector-714127049161.europe-west1.run.app`](https://ai-product-detector-714127049161.europe-west1.run.app) |
| **UI** | europe-west1 | [`ai-product-detector-ui-714127049161.europe-west1.run.app`](https://ai-product-detector-ui-714127049161.europe-west1.run.app) |

**Configuration:** 1 GiB memory, port 8080, auto-scaling 0â†’N, health probes on `/health`

### Terraform Resources

```bash
cd terraform/environments/prod
terraform init && terraform apply
```

Provisions via modular architecture:
- **storage/** â€” GCS bucket with versioning
- **artifact_registry/** â€” Docker image registry
- **cloud_run/** â€” API and UI services
- **iam/** â€” Service accounts and bindings
- **budget/** â€” Cost alerts and quotas
- **secrets/** â€” API keys via Secret Manager
- **vertex_ai/** â€” Training job configuration

### Deployment Flows

```bash
# Automatic: push to main
git push origin main  # â†’ CI â†’ CD â†’ Cloud Run

# Manual deploy
make deploy  # or: gh workflow run cd.yml

# Rollback
gh workflow run cd.yml -f image_tag=<commit-sha>
```

---

## ğŸ¤ Contributing

Contributions welcome â€” please read [`docs/CONTRIBUTING.md`](docs/CONTRIBUTING.md) first.

```bash
make dev             # Install dev dependencies + pre-commit hooks
make lint            # Ruff + mypy
make test            # pytest with coverage
```

**Conventions:**
- [Conventional commits](https://www.conventionalcommits.org/) â€” `feat:`, `fix:`, `docs:`, `refactor:`, `test:`
- Ruff for linting & formatting
- mypy for type checking
- Pre-commit hooks enforced

---

## ğŸ“š Documentation

Detailed documentation is available in the [`docs/`](docs/) folder:

| Document | Description |
|----------|-------------|
| [`ARCHITECTURE.md`](docs/ARCHITECTURE.md) | System architecture & design decisions |
| [`CICD.md`](docs/CICD.md) | CI/CD pipeline documentation |
| [`CONTRIBUTING.md`](docs/CONTRIBUTING.md) | Contribution guidelines |
| [`COSTS.md`](docs/COSTS.md) | Cloud cost analysis |
| [`DEPLOYMENT.md`](docs/DEPLOYMENT.md) | Deployment guide |
| [`INCIDENT_SCENARIO.md`](docs/INCIDENT_SCENARIO.md) | Incident response playbook |
| [`INFRASTRUCTURE.md`](docs/INFRASTRUCTURE.md) | Infrastructure documentation |
| [`MONITORING.md`](docs/MONITORING.md) | Monitoring & observability guide |
| [`PRD.md`](docs/PRD.md) | Product requirements document |
| [`TRAINING.md`](docs/TRAINING.md) | Training pipeline documentation |

---

## ğŸ“„ License

This project is licensed under the MIT License â€” see [LICENSE](LICENSE) for details.

---

<p align="center">
  Built by <a href="https://github.com/nolancacheux">Nolan Cacheux</a>
</p>
